{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji\n",
    "!pip install stop-words\n",
    "!pip install transformers datasets imblearn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments,EarlyStoppingCallback,AutoModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import emoji\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "import nltk\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import random\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/final-dataset/final_full_data_main.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['label'].value_counts()\n",
    "print(\"Count of tweets with label 1.0 (sarcastic):\", label_counts[1.0])\n",
    "print(\"Count of tweets with label 0.0 (non-sarcastic):\", label_counts[0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainf, X_test, y_trainf, y_test = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=seed, stratify=df['label']\n",
    ")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_trainf, y_trainf, test_size=0.1, random_state=seed, stratify=y_trainf\n",
    ")\n",
    "\n",
    "X_train = X_train.astype(str)\n",
    "X_test = X_test.astype(str)\n",
    "X_valid = X_valid.astype(str)\n",
    "\n",
    "y_train = pd.Series(y_train).reset_index(drop=True)\n",
    "y_test = pd.Series(y_test).reset_index(drop=True)\n",
    "y_valid = pd.Series(y_valid).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcasmDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=150):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the training dataset using Oversampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=seed)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train.to_frame(), y_train)\n",
    "\n",
    "label_counts12 = y_train_resampled.value_counts()\n",
    "print(\"Count of tweets with label 1.0 (sarcastic):\", label_counts12[1.0])\n",
    "print(\"Count of tweets with label 0.0 (non-sarcastic):\", label_counts12[0.0])\n",
    "\n",
    "X_train_resampled = X_train_resampled['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SarcasmDataset(\n",
    "    texts=X_train_resampled.tolist(),\n",
    "    labels=y_train_resampled.tolist(),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "valid_dataset = SarcasmDataset(\n",
    "    texts=X_valid.tolist(),\n",
    "    labels=y_valid.tolist(),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "test_dataset = SarcasmDataset(\n",
    "    texts=X_test.tolist(),\n",
    "    labels=y_test.tolist(),\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai4bharat/indic-bert\", num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"Train accuracy\": accuracy_score(p.label_ids, preds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting training and validation losses by epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_history = trainer.state.log_history\n",
    "\n",
    "epoch_train_losses = {}\n",
    "epoch_eval_losses = {}\n",
    "\n",
    "for entry in log_history:\n",
    "    if 'epoch' in entry:\n",
    "        epoch = int(entry['epoch'])\n",
    "        # Record training loss if present (last one encountered per epoch is used)\n",
    "        if 'loss' in entry:\n",
    "            epoch_train_losses[epoch] = entry['loss']\n",
    "        # Record evaluation loss if present\n",
    "        if 'eval_loss' in entry:\n",
    "            epoch_eval_losses[epoch] = entry['eval_loss']\n",
    "\n",
    "# Only consider epochs that have both training and eval losses\n",
    "common_epochs = sorted(set(epoch_train_losses.keys()) & set(epoch_eval_losses.keys()))\n",
    "final_train_losses = [epoch_train_losses[e] for e in common_epochs]\n",
    "final_eval_losses = [epoch_eval_losses[e] for e in common_epochs]\n",
    "\n",
    "for epoch, (train_loss, eval_loss) in enumerate(zip(final_train_losses, final_eval_losses), start=1):\n",
    "    print(f\"Epoch {epoch}: Training Loss = {train_loss:.4f}, Validation Loss = {eval_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(common_epochs, final_train_losses, label=\"Training Loss\", marker=\"o\")\n",
    "plt.plot(common_epochs, final_eval_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = np.argmax(test_predictions.predictions, axis=1)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_test, predicted_labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Reds')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
